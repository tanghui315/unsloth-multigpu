"""
Unsloth Multi-GPU Advanced Configuration Example
This example demonstrates how to use Unsloth Multi-GPU's advanced features and configuration options
"""

import os

import torch
from datasets import load_dataset
from transformers import TrainingArguments

import unsloth_multigpu_prototype as unsloth_multigpu
from unsloth import FastLanguageModel, unsloth_train
from unsloth_multigpu_prototype.utils import (ConfigManager, DeviceManager,
                                              MultiGPULogger)


def main():
    # 1. åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger = MultiGPULogger(
        log_dir="./logs",
        log_level="INFO",
        enable_tensorboard=True
    )
    logger.info("ğŸš€ å¼€å§‹Unslothå¤šGPUé«˜çº§é…ç½®ç¤ºä¾‹")

    # 2. è®¾å¤‡ç®¡ç†
    device_manager = DeviceManager()
    devices = device_manager.get_available_devices()
    logger.info(f"ğŸ“Š å¯ç”¨GPU: {devices}")

    # 3. é…ç½®ç®¡ç†
    config_manager = ConfigManager()
    optimal_config = config_manager.get_optimal_config(
        model_size="7B",
        available_memory="32GB",
        num_gpus=len(devices)
    )
    logger.info(f"âš™ï¸ æ¨èé…ç½®: {optimal_config}")

    # 4. å¯ç”¨å¤šGPUï¼ˆä½¿ç”¨ä¼˜åŒ–é…ç½®ï¼‰
    logger.info("ğŸ”„ å¯ç”¨å¤šGPUæ”¯æŒ...")
    unsloth_multigpu.enable_multi_gpu(
        **optimal_config,
        gradient_aggregation="weighted_mean",  # ä½¿ç”¨åŠ æƒå¹³å‡èšåˆ
        memory_efficient=True,  # å¯ç”¨å†…å­˜ä¼˜åŒ–
        enable_profiling=True   # å¯ç”¨æ€§èƒ½åˆ†æ
    )

    # 5. æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    status = unsloth_multigpu.get_multi_gpu_status()
    logger.info(f"ğŸ“Š å¤šGPUçŠ¶æ€: {status}")

    # 6. åŠ è½½æ¨¡å‹
    logger.info("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    model, tokenizer = FastLanguageModel.from_pretrained(
        "unsloth/llama-2-7b-bnb-4bit",
        max_seq_length=2048,
        dtype="bfloat16",
        load_in_4bit=True
    )

    # 7. å‡†å¤‡æ•°æ®é›†
    logger.info("ğŸ“š å‡†å¤‡æ•°æ®é›†...")
    dataset = load_dataset("tatsu-lab/alpaca", split="train")
    
    def formatting_prompts_func(example):
        output_texts = []
        for i in range(len(example['instruction'])):
            text = f"### Instruction:\n{example['instruction'][i]}\n\n"
            if example['input'][i]:
                text += f"### Input:\n{example['input'][i]}\n\n"
            text += f"### Response:\n{example['output'][i]}"
            output_texts.append(text)
        return output_texts

    # 8. é…ç½®è®­ç»ƒå‚æ•°
    logger.info("âš™ï¸ é…ç½®è®­ç»ƒå‚æ•°...")
    training_args = TrainingArguments(
        output_dir="./results",
        num_train_epochs=3,
        per_device_train_batch_size=optimal_config["batch_size"],
        gradient_accumulation_steps=4,
        learning_rate=2e-4,
        fp16=True,
        logging_steps=10,
        save_strategy="epoch",
        warmup_ratio=0.1,
        # é«˜çº§è®­ç»ƒé…ç½®
        gradient_checkpointing=True,  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
        optim="adamw_torch",         # ä½¿ç”¨PyTorchçš„AdamWä¼˜åŒ–å™¨
        lr_scheduler_type="cosine",  # ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
        weight_decay=0.01,          # æƒé‡è¡°å‡
        max_grad_norm=1.0,          # æ¢¯åº¦è£å‰ª
    )

    # 9. å¼€å§‹è®­ç»ƒ
    logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
    trainer_stats = unsloth_train(
        model=model,
        tokenizer=tokenizer,
        train_dataset=dataset,
        formatting_prompts_func=formatting_prompts_func,
        training_args=training_args
    )

    # 10. ä¿å­˜è®­ç»ƒç»Ÿè®¡
    logger.info("ğŸ’¾ ä¿å­˜è®­ç»ƒç»Ÿè®¡...")
    logger.save_training_stats(trainer_stats, "training_stats.json")

    logger.info("âœ… è®­ç»ƒå®Œæˆ!")
    logger.info(f"ğŸ“Š è®­ç»ƒç»Ÿè®¡: {trainer_stats}")

if __name__ == "__main__":
    main() 