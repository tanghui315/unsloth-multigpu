"""
DDP Trainer - åŸºäºPyTorch DDPçš„åˆ†å¸ƒå¼è®­ç»ƒå™¨
æ›¿æ¢åŸæœ‰çš„ä½æ•ˆä¸²è¡Œè®­ç»ƒå®ç°
"""

import logging
import time
from typing import Any, Dict, Optional, Union

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, DistributedSampler
from transformers import Trainer

from .ddp_manager import DDPManager
from ..utils import MultiGPUConfig

logger = logging.getLogger(__name__)


class DDPTrainer:
    """
    DDP Trainer - åŸºäºPyTorchåŸç”ŸDDPçš„é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒå™¨
    
    ä¸»è¦ä¼˜åŠ¿ï¼š
    1. çœŸæ­£çš„å¹¶è¡Œè®­ç»ƒï¼ˆvs åŸæ¥çš„ä¸²è¡Œï¼‰
    2. è‡ªåŠ¨æ¢¯åº¦åŒæ­¥ï¼ˆvs æ‰‹åŠ¨CPUä¼ è¾“ï¼‰
    3. é«˜æ•ˆçš„NCCLé€šä¿¡ï¼ˆvs ä½æ•ˆçš„èšåˆï¼‰
    4. åŸç”ŸPyTorchæ”¯æŒï¼ˆvs è‡ªåˆ¶è½®å­ï¼‰
    """
    
    def __init__(self, 
                 original_trainer: Trainer,
                 config: MultiGPUConfig,
                 ddp_manager: Optional[DDPManager] = None):
        """
        åˆå§‹åŒ–DDPè®­ç»ƒå™¨
        
        Args:
            original_trainer: åŸå§‹HuggingFace Trainer
            config: å¤šGPUé…ç½®
            ddp_manager: DDPç®¡ç†å™¨ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨åˆ›å»º
        """
        self.original_trainer = original_trainer
        self.config = config
        self.ddp_manager = ddp_manager or DDPManager()
        
        # æ¨¡å‹å’Œä¼˜åŒ–å™¨
        self.model = original_trainer.model
        self.ddp_model = None
        self.optimizer = None
        
        # æ•°æ®ç›¸å…³
        self.train_dataset = original_trainer.train_dataset
        self.data_collator = original_trainer.data_collator
        self.train_dataloader = None
        
        # è®­ç»ƒçŠ¶æ€
        self.global_step = 0
        self.epoch = 0
        self.is_setup = False
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_train_time': 0.0,
            'total_forward_time': 0.0,
            'total_backward_time': 0.0,
            'total_samples': 0,
            'steps_per_second': 0.0
        }
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ–DDPTrainer: {config.num_gpus} GPUs")
    
    def setup(self, rank: int):
        """
        è®¾ç½®DDPè®­ç»ƒç¯å¢ƒ
        
        Args:
            rank: å½“å‰è¿›ç¨‹rank
        """
        if self.is_setup:
            return
            
        logger.info(f"ğŸš€ è®¾ç½®DDPè®­ç»ƒç¯å¢ƒ (rank={rank})...")
        
        # 1. åˆå§‹åŒ–DDPè¿›ç¨‹ç»„
        success = self.ddp_manager.init_process_group(
            rank=rank,
            world_size=self.config.num_gpus
        )
        if not success:
            raise RuntimeError(f"DDPè¿›ç¨‹ç»„åˆå§‹åŒ–å¤±è´¥ (rank={rank})")
        
        # 2. åŒ…è£…æ¨¡å‹ä¸ºDDP
        self.ddp_model = self.ddp_manager.wrap_model(
            self.model,
            find_unused_parameters=getattr(self.config, 'find_unused_parameters', False)
        )
        
        # 3. åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆå¿…é¡»åœ¨DDPåŒ…è£…åï¼‰
        self._setup_optimizer()
        
        # 4. åˆ›å»ºåˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨
        self._setup_dataloader()
        
        self.is_setup = True
        
        if self.ddp_manager.is_master:
            logger.info("âœ… DDPè®­ç»ƒç¯å¢ƒè®¾ç½®å®Œæˆ")
    
    def _setup_optimizer(self):
        """è®¾ç½®ä¼˜åŒ–å™¨"""
        # ä»åŸå§‹traineræå–ä¼˜åŒ–å™¨é…ç½®
        training_args = self.original_trainer.args
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        if hasattr(self.original_trainer, 'create_optimizer'):
            # ä½¿ç”¨HuggingFaceçš„ä¼˜åŒ–å™¨åˆ›å»ºæ–¹æ³•
            self.original_trainer.model = self.ddp_model
            self.original_trainer.create_optimizer()
            self.optimizer = self.original_trainer.optimizer
        else:
            # fallbackåˆ°é»˜è®¤AdamW
            self.optimizer = torch.optim.AdamW(
                self.ddp_model.parameters(),
                lr=training_args.learning_rate,
                weight_decay=training_args.weight_decay,
                eps=training_args.adam_epsilon
            )
        
        if self.ddp_manager.is_master:
            logger.info(f"âœ… ä¼˜åŒ–å™¨è®¾ç½®å®Œæˆ: {type(self.optimizer).__name__}")
    
    def _setup_dataloader(self):
        """è®¾ç½®åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨"""
        # åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
        sampler = self.ddp_manager.create_data_sampler(
            self.train_dataset,
            shuffle=True
        )
        
        # åˆ›å»ºDataLoader
        self.train_dataloader = DataLoader(
            self.train_dataset,
            sampler=sampler,
            batch_size=self.config.batch_size_per_gpu,
            collate_fn=self.data_collator,
            num_workers=getattr(self.config, 'dataloader_num_workers', 0),
            pin_memory=True
        )
        
        if self.ddp_manager.is_master:
            logger.info(f"âœ… åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨è®¾ç½®å®Œæˆ: batch_size={self.config.batch_size_per_gpu}")
    
    def train_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•æ­¥è®­ç»ƒ
        
        Args:
            batch: è®­ç»ƒæ‰¹æ¬¡æ•°æ®
            
        Returns:
            Dict: è®­ç»ƒç»“æœç»Ÿè®¡
        """
        step_start = time.time()
        
        # ç§»åŠ¨æ•°æ®åˆ°GPU
        device = f"cuda:{self.ddp_manager.local_rank}"
        batch = {k: v.to(device, non_blocking=True) if isinstance(v, torch.Tensor) else v 
                for k, v in batch.items()}
        
        # æ¢¯åº¦æ¸…é›¶
        self.optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        forward_start = time.time()
        
        # æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ
        if getattr(self.config, 'fp16', False):
            with torch.cuda.amp.autocast():
                outputs = self.ddp_model(**batch)
                loss = outputs.loss
        else:
            outputs = self.ddp_model(**batch)
            loss = outputs.loss
        
        forward_time = time.time() - forward_start
        
        # åå‘ä¼ æ’­ï¼ˆDDPè‡ªåŠ¨åŒæ­¥æ¢¯åº¦ï¼‰
        backward_start = time.time()
        loss.backward()
        backward_time = time.time() - backward_start
        
        # æ¢¯åº¦è£å‰ª
        if getattr(self.config, 'max_grad_norm', None):
            torch.nn.utils.clip_grad_norm_(
                self.ddp_model.parameters(), 
                self.config.max_grad_norm
            )
        
        # ä¼˜åŒ–å™¨æ­¥éª¤
        self.optimizer.step()
        
        # æ›´æ–°å…¨å±€æ­¥æ•°
        self.global_step += 1
        
        # ç»Ÿè®¡ä¿¡æ¯
        step_time = time.time() - step_start
        batch_size = batch['input_ids'].size(0)
        
        self.stats['total_forward_time'] += forward_time
        self.stats['total_backward_time'] += backward_time
        self.stats['total_samples'] += batch_size
        
        return {
            'loss': loss.item(),
            'learning_rate': self.optimizer.param_groups[0]['lr'],
            'step_time': step_time,
            'forward_time': forward_time,
            'backward_time': backward_time,
            'throughput': batch_size / step_time,
            'global_step': self.global_step
        }
    
    def train_epoch(self) -> Dict[str, Any]:
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        Returns:
            Dict: epochè®­ç»ƒç»Ÿè®¡
        """
        if not self.is_setup:
            raise RuntimeError("DDPè®­ç»ƒå™¨æœªè®¾ç½®ï¼Œè¯·å…ˆè°ƒç”¨setup()")
        
        epoch_start = time.time()
        epoch_loss = 0.0
        num_steps = 0
        
        # è®¾ç½®é‡‡æ ·å™¨çš„epochï¼ˆç¡®ä¿æ¯ä¸ªepochæ•°æ®é¡ºåºä¸åŒï¼‰
        if hasattr(self.train_dataloader.sampler, 'set_epoch'):
            self.train_dataloader.sampler.set_epoch(self.epoch)
        
        self.ddp_model.train()
        
        if self.ddp_manager.is_master:
            logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒ epoch {self.epoch}")
        
        for batch_idx, batch in enumerate(self.train_dataloader):
            step_result = self.train_step(batch)
            epoch_loss += step_result['loss']
            num_steps += 1
            
            # å®šæœŸæ‰“å°è¿›åº¦ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
            if self.ddp_manager.is_master and batch_idx % 10 == 0:
                logger.info(
                    f"Epoch {self.epoch}, Step {batch_idx}/{len(self.train_dataloader)}, "
                    f"Loss: {step_result['loss']:.4f}, "
                    f"LR: {step_result['learning_rate']:.2e}, "
                    f"Throughput: {step_result['throughput']:.1f} samples/s"
                )
        
        # Epochç»Ÿè®¡
        epoch_time = time.time() - epoch_start
        avg_loss = epoch_loss / num_steps if num_steps > 0 else 0.0
        
        self.epoch += 1
        self.stats['total_train_time'] += epoch_time
        self.stats['steps_per_second'] = num_steps / epoch_time
        
        epoch_stats = {
            'epoch': self.epoch - 1,
            'avg_loss': avg_loss,
            'epoch_time': epoch_time,
            'num_steps': num_steps,
            'steps_per_second': self.stats['steps_per_second']
        }
        
        if self.ddp_manager.is_master:
            logger.info(f"âœ… Epoch {self.epoch-1} å®Œæˆ: "
                       f"avg_loss={avg_loss:.4f}, "
                       f"time={epoch_time:.1f}s, "
                       f"steps/s={epoch_stats['steps_per_second']:.1f}")
        
        return epoch_stats
    
    def train(self, num_epochs: Optional[int] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´è®­ç»ƒ
        
        Args:
            num_epochs: è®­ç»ƒè½®æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é…ç½®ä¸­çš„å€¼
            
        Returns:
            Dict: è®­ç»ƒç»“æœç»Ÿè®¡
        """
        if num_epochs is None:
            num_epochs = getattr(self.config, 'num_train_epochs', 3)
        
        train_start = time.time()
        all_epoch_stats = []
        
        if self.ddp_manager.is_master:
            logger.info(f"ğŸš€ å¼€å§‹DDPè®­ç»ƒ: {num_epochs} epochs, {self.config.num_gpus} GPUs")
        
        try:
            for epoch_idx in range(num_epochs):
                epoch_stats = self.train_epoch()
                all_epoch_stats.append(epoch_stats)
            
            # æœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - train_start
            final_stats = {
                'total_time': total_time,
                'num_epochs': num_epochs,
                'total_steps': self.global_step,
                'avg_steps_per_second': self.global_step / total_time,
                'total_samples': self.stats['total_samples'],
                'epoch_stats': all_epoch_stats,
                'performance_stats': self.stats
            }
            
            if self.ddp_manager.is_master:
                logger.info(f"ğŸ‰ DDPè®­ç»ƒå®Œæˆ! "
                           f"æ€»æ—¶é—´: {total_time:.1f}s, "
                           f"æ€»æ­¥æ•°: {self.global_step}, "
                           f"å¹³å‡é€Ÿåº¦: {final_stats['avg_steps_per_second']:.1f} steps/s")
            
            return final_stats
            
        except Exception as e:
            logger.error(f"âŒ DDPè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise
        finally:
            # æ¸…ç†èµ„æº
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†DDPèµ„æº"""
        try:
            self.ddp_manager.cleanup()
            if self.ddp_manager.is_master:
                logger.info("âœ… DDPèµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸ DDPæ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°è­¦å‘Š: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        return {
            'ddp_stats': self.ddp_manager.get_status(),
            'training_stats': self.stats.copy(),
            'config': {
                'num_gpus': self.config.num_gpus,
                'batch_size_per_gpu': self.config.batch_size_per_gpu,
                'gradient_aggregation': self.config.gradient_aggregation
            }
        }
    
    def __del__(self):
        """ææ„å‡½æ•°"""
        try:
            self.cleanup()
        except:
            pass