# Unslothå¤šGPUæ”¯æŒåº“

ä¸ºUnslothæ¡†æ¶æä¾›å¤šGPUå¹¶è¡Œè®­ç»ƒæ”¯æŒçš„å¤–éƒ¨æ‰©å±•åŒ…ã€‚

## ğŸ¯ é¡¹ç›®ç‰¹ç‚¹

- **é›¶ä¾µå…¥æ€§è®¾è®¡**: æ— éœ€ä¿®æ”¹Unslothæºç 
- **æ’ä»¶åŒ–æ¶æ„**: ä½œä¸ºç‹¬ç«‹æ‰©å±•åŒ…è¿è¡Œ
- **å®Œå…¨å…¼å®¹**: ä¸Unslothå¼€æºç‰ˆæœ¬ä¿æŒåŒæ­¥
- **ç®€å•æ˜“ç”¨**: åªéœ€æ·»åŠ ä¸€è¡Œå¯¼å…¥è¯­å¥

## ğŸ“¦ å®‰è£…è¦æ±‚

### å¿«é€Ÿå®‰è£…
```bash
# å…‹éš†é¡¹ç›®å¹¶å®‰è£…
git clone https://github.com/tanghui315/unsloth-multigpu.git
cd unsloth-multigpu
pip install .
```

### è¯¦ç»†ä¾èµ–è¦æ±‚
æœ¬é¡¹ç›®ä¾èµ–ä»¥ä¸‹åŒ…ï¼ˆå®‰è£…æ—¶ä¼šè‡ªåŠ¨å¤„ç†ï¼‰ï¼š
- Unsloth (æä¾›FastLanguageModelå’ŒLoRAæ”¯æŒ)
- TRL (æä¾›SFTTrainerç”¨äºç›‘ç£å¼å¾®è°ƒ)
- PyTorch (GPUç‰ˆæœ¬)
- Transformers, datasets, accelerate
- psutil, PyYAMLï¼ˆç”¨äºå†…å­˜ç®¡ç†å’Œé…ç½®ï¼‰

### âš ï¸ é‡è¦è¯´æ˜
ç¡®ä¿ç³»ç»Ÿä¸­æœ‰CUDAæ”¯æŒã€‚å¦‚æœé‡åˆ°å¯¼å…¥é”™è¯¯ï¼Œè¯·è¿è¡ŒéªŒè¯è„šæœ¬ï¼š
```bash
python examples/verify_installation.py
```

### å¯é€‰ä¾èµ–
```bash
# TensorBoardæ”¯æŒ
pip install tensorboard

# W&Bæ”¯æŒ
pip install wandb
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1: Hookæœºåˆ¶ï¼ˆæ¨èç”¨äºç°æœ‰ä»£ç ï¼‰

#### è¿è¡Œç¤ºä¾‹
```bash
# æ–¹å¼1: å•è¿›ç¨‹è¿è¡Œï¼ˆHookä¼šæç¤ºä½¿ç”¨torchrunï¼‰
python examples/quick_start.py

# æ–¹å¼2: ä½¿ç”¨torchrunè¿›è¡ŒçœŸæ­£çš„DDPè®­ç»ƒï¼ˆæ¨èï¼‰
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 examples/quick_start.py
```

#### ä»£ç ç¤ºä¾‹
```python
import unsloth_multigpu as unsloth_multigpu
from unsloth import FastLanguageModel
from trl import SFTTrainer
from transformers import TrainingArguments

# 1. å¯ç”¨å¤šGPUæ”¯æŒï¼ˆHookæœºåˆ¶ï¼‰
unsloth_multigpu.enable_multi_gpu(
    num_gpus=2,  # ä½¿ç”¨2ä¸ªGPU
    batch_size_per_gpu=2,  # æ¯ä¸ªGPUçš„æ‰¹æ¬¡å¤§å°
    ddp_backend="nccl",  # DDPé€šä¿¡åç«¯
    enable_memory_optimization=True  # å¯ç”¨å†…å­˜ä¼˜åŒ–
)

# 2. åŠ è½½æ¨¡å‹ï¼ˆè‡ªåŠ¨æ”¯æŒå¤šGPUï¼‰
model, tokenizer = FastLanguageModel.from_pretrained(
    "/path/to/your/model",  # æ¨¡å‹è·¯å¾„
    max_seq_length=4096,
    dtype=torch.bfloat16,  # æ³¨æ„ï¼šä½¿ç”¨torch.bfloat16è€Œä¸æ˜¯å­—ç¬¦ä¸²
    load_in_4bit=True
)

# 3. é…ç½®LoRAï¼ˆunslothè®­ç»ƒå¿…éœ€ï¼‰
model = FastLanguageModel.get_peft_model(
    model,
    r=16,  # LoRAç§©
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                   "gate_proj", "up_proj", "down_proj"],
    lora_alpha=16,
    lora_dropout=0,
    bias="none",
    use_gradient_checkpointing="unsloth",
    random_state=3407,
)

# 4. é…ç½®è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=2,  # è¿™å°†è¢«å¤šGPUå¤„ç†
    learning_rate=2e-5,
    logging_steps=1,
    save_strategy="steps",
    save_steps=100,
)

# 5. åˆ›å»ºSFTTrainerå¹¶è®­ç»ƒï¼ˆè‡ªåŠ¨æ”¯æŒå¤šGPUï¼‰
trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    dataset_text_field="text",  # æˆ–ä½¿ç”¨formatting_func
    args=training_args,
    max_seq_length=4096,
)

trainer_stats = trainer.train()
```

### æ–¹å¼3: GRPOå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼ˆMulti-GPUæ”¯æŒï¼‰

GRPO (Generalized Reinforcement Learning from Policy Optimization) æ˜¯ä¸€ç§å…ˆè¿›çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ–¹æ³•ï¼Œæ”¯æŒå¤šGPUå¹¶è¡Œè®­ç»ƒã€‚

#### GRPOè®­ç»ƒå®Œæ•´æ­¥éª¤

**æ­¥éª¤1: å¯åŠ¨vLLMæ¨ç†æœåŠ¡**ï¼ˆå¦‚æœä½¿ç”¨vLLMæ¨ç†ï¼‰
```bash
# å¯åŠ¨vLLMæœåŠ¡ç”¨äºå¿«é€Ÿæ¨ç†ï¼ˆåœ¨å•ç‹¬ç»ˆç«¯ä¸­è¿è¡Œï¼‰
CUDA_VISIBLE_DEVICES=0,1 trl vllm-serve \
    --model /path/to/your/model \
    --tensor-parallel-size 2 \
    --port 8000
```

**æ­¥éª¤2: å¯ç”¨GRPOæ”¯æŒå¹¶è¿›è¡Œå¤šGPUè®­ç»ƒ**
```bash
# ä½¿ç”¨torchrunå¯åŠ¨å¤šGPU GRPOè®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 examples/grpo_open_r1_multi_gpu.py
```

#### GRPOè®­ç»ƒä»£ç ç¤ºä¾‹
```python
import unsloth_multigpu as ump
from unsloth import FastLanguageModel
from trl import GRPOTrainer, GRPOConfig

# 1. å¯ç”¨GRPOæ”¯æŒ
ump.enable_grpo_support()

# 2. å¯ç”¨å¤šGPUæ”¯æŒ
ump.enable_multi_gpu(
    num_gpus=2,
    batch_size_per_gpu=1,
    ddp_backend="nccl",
    enable_memory_optimization=True
)

# 3. åŠ è½½æ¨¡å‹
model, tokenizer = FastLanguageModel.from_pretrained(
    "Qwen/Qwen2.5-3B-Instruct",
    max_seq_length=8192,
    load_in_4bit=True,
)

# 4. é…ç½®LoRA
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_alpha=32,
    use_gradient_checkpointing="unsloth",
)

# 5. é…ç½®GRPOè®­ç»ƒå‚æ•°
training_args = GRPOConfig(
    output_dir="./grpo_output",
    num_generations=8,
    learning_rate=5e-6,
    per_device_train_batch_size=1,
    gradient_checkpointing=True,
    use_vllm=True,  # ä½¿ç”¨vLLMåŠ é€Ÿæ¨ç†
    vllm_server_host="127.0.0.1",
    vllm_server_port=8000,
)

# 6. å‡†å¤‡å¥–åŠ±å‡½æ•°ï¼ˆéœ€è¦open-r1æ”¯æŒï¼‰
from open_r1.rewards import get_reward_funcs
reward_funcs = get_reward_funcs(script_args)

# 7. åˆ›å»ºGRPOè®­ç»ƒå™¨
trainer = GRPOTrainer(
    model=model,
    reward_funcs=reward_funcs,
    args=training_args,
    train_dataset=dataset,
    processing_class=tokenizer,
)

# 8. å¼€å§‹è®­ç»ƒ
trainer.train()
```

#### GRPOè®­ç»ƒé…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼ˆYAMLï¼‰
```yaml
# examples/configs/grpo_open_r1_config.yaml
model_name_or_path: Qwen/Qwen2.5-32B-Instruct
dataset_name: data/grpo_data.jsonl

# GRPOç‰¹å®šé…ç½®
use_vllm: true
vllm_server_host: 127.0.0.1
vllm_server_port: 8000
num_generations: 8
learning_rate: 5.0e-06
per_device_train_batch_size: 1

# å¥–åŠ±å‡½æ•°é…ç½®
reward_funcs:
  - accuracy
  - format
  - reasoning_steps
  - cosine
  - repetition_penalty
  - length

# LoRAé…ç½®
lora_r: 16
gradient_checkpointing: true
```

#### é‡è¦è¯´æ˜ï¼šä¸¤ç§è¿è¡Œæ–¹å¼çš„åŒºåˆ«

1. **å•è¿›ç¨‹è¿è¡Œ**ï¼ˆ`python script.py`ï¼‰ï¼š
   - Hookæ£€æµ‹åˆ°å¤šGPUéœ€æ±‚ï¼Œä¼šæç¤ºä½¿ç”¨torchrun
   - æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯å’Œæ­£ç¡®çš„å¯åŠ¨å‘½ä»¤
   - é€‚åˆæµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®

2. **torchrunè¿è¡Œ**ï¼ˆ`torchrun --nproc_per_node=2 script.py`ï¼‰ï¼š
   - å¯åŠ¨çœŸæ­£çš„DDPå¤šè¿›ç¨‹è®­ç»ƒ
   - æ¯ä¸ªGPUè¿è¡Œä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹
   - è‡ªåŠ¨æ•°æ®åˆ†å‰²å’Œæ¢¯åº¦åŒæ­¥
   - è·å¾—çœŸæ­£çš„æ€§èƒ½æå‡

```bash
# å¦‚æœè¿è¡Œæ™®é€šå‘½ä»¤ï¼Œä¼šçœ‹åˆ°ç±»ä¼¼æç¤ºï¼š
$ python examples/quick_start.py
âŒ å¤šGPUè®­ç»ƒéœ€è¦ä½¿ç”¨torchrunå¯åŠ¨
ğŸ’¡ è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨:
   CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 examples/quick_start.py
```

### æ–¹å¼2: ç›´æ¥ä½¿ç”¨ï¼ˆæ¨èç”¨äºæ–°é¡¹ç›®ï¼‰
```python
from unsloth_multigpu.core import MultiGPUTrainer, AggregationMethod
from unsloth import FastLanguageModel

# 1. åŠ è½½æ¨¡å‹
model, tokenizer = FastLanguageModel.from_pretrained("model_name")

# 2. é…ç½®ä¼˜åŒ–å™¨
optimizer_config = {
    'class': torch.optim.AdamW,
    'kwargs': {'lr': 2e-5, 'weight_decay': 0.01}
}

# 3. ç›´æ¥åˆ›å»ºå¤šGPUè®­ç»ƒå™¨
trainer = MultiGPUTrainer(
    model=model,
    num_gpus=4,
    optimizer_config=optimizer_config,
    aggregation_method=AggregationMethod.MEAN
)

# 4. è®­ç»ƒ
trainer.setup()
epoch_stats = trainer.train_epoch(dataloader)
```

### é«˜çº§é…ç½®
```python
from unsloth_multigpu.utils import ConfigManager, DeviceManager

# 1. è®¾å¤‡ç®¡ç†
device_manager = DeviceManager()
devices = device_manager.get_available_devices()

# 2. è·å–æœ€ä¼˜é…ç½®
config_manager = ConfigManager()
optimal_config = config_manager.get_optimal_config(
    model_size="7B",
    available_memory="32GB"
)

# 3. å¯ç”¨å¤šGPUï¼ˆä½¿ç”¨ä¼˜åŒ–é…ç½®ï¼‰
unsloth_multigpu.enable_multi_gpu(**optimal_config)
```

## ğŸ› ï¸ æ ¸å¿ƒåŠŸèƒ½

### 1. å¤šGPUç®¡ç†
- è‡ªåŠ¨æ£€æµ‹å’Œé…ç½®GPUè®¾å¤‡
- æ™ºèƒ½è´Ÿè½½å‡è¡¡
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–

### 2. æ‰¹æ¬¡åˆ†ç‰‡
- æ”¯æŒä¸å‡åŒ€åˆ†ç‰‡
- è‡ªé€‚åº”åˆ†ç‰‡ç­–ç•¥
- é«˜æ•ˆç»“æœæ”¶é›†

### 3. DDPè®­ç»ƒæ”¯æŒ
- PyTorchåŸç”ŸDDPå®ç°
- è‡ªåŠ¨æ¢¯åº¦åŒæ­¥
- é«˜æ•ˆçš„NCCLé€šä¿¡

### 4. å†…å­˜ç®¡ç†
- å®æ—¶å†…å­˜ç›‘æ§
- OOMé¢„é˜²æœºåˆ¶
- è‡ªåŠ¨å†…å­˜æ¸…ç†

### 5. é…ç½®ç®¡ç†
- è‡ªåŠ¨ç¯å¢ƒæ£€æµ‹
- æœ€ä¼˜é…ç½®ç”Ÿæˆ
- é…ç½®éªŒè¯å’Œæ¨¡æ¿

## ğŸ“Š æ€§èƒ½ç‰¹æ€§

- **è®­ç»ƒé€Ÿåº¦æå‡**: æ”¯æŒ3.5-4å€é€Ÿåº¦æå‡ï¼ˆ4GPUç¯å¢ƒï¼‰
- **å†…å­˜ä¼˜åŒ–**: æ™ºèƒ½å†…å­˜ç®¡ç†ï¼Œé™ä½OOMé£é™©
- **ç¨³å®šæ€§**: å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
- **ç›‘æ§**: å®æ—¶æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•

## ğŸ§ª æµ‹è¯•

è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶ï¼š
```bash
cd unsloth_multigpu
python tests/run_all_tests.py
```

è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼š
```bash
python tests/run_all_tests.py --quick
```

## ğŸ“– ç¤ºä¾‹

æŸ¥çœ‹ `examples/` ç›®å½•ä¸­çš„ç¤ºä¾‹ï¼š
- `quick_start.py`: Hookæœºåˆ¶åŸºç¡€ç¤ºä¾‹ï¼ˆé›¶ä¾µå…¥æ€§ï¼‰
- `advanced_config.py`: Hookæœºåˆ¶é«˜çº§é…ç½®ç¤ºä¾‹  
- `direct_trainer_usage.py`: ç›´æ¥ä½¿ç”¨MultiGPUTrainerç¤ºä¾‹
- `grpo_open_r1_multi_gpu.py`: GRPOå¼ºåŒ–å­¦ä¹ å¤šGPUè®­ç»ƒç¤ºä¾‹
- `configs/grpo_open_r1_config.yaml`: GRPOè®­ç»ƒYAMLé…ç½®ç¤ºä¾‹
- `verify_installation.py`: å®‰è£…éªŒè¯è„šæœ¬

### é€‰æ‹©åˆé€‚çš„æ–¹å¼
- **ç°æœ‰é¡¹ç›®è¿ç§»**: ä½¿ç”¨ `quick_start.py` çš„Hookæ–¹å¼
- **æ–°é¡¹ç›®å¼€å‘**: ä½¿ç”¨ `direct_trainer_usage.py` çš„ç›´æ¥æ–¹å¼
- **GRPOå¼ºåŒ–å­¦ä¹ è®­ç»ƒ**: ä½¿ç”¨ `grpo_open_r1_multi_gpu.py` è¿›è¡Œå¤šGPU GRPOè®­ç»ƒ
- **é«˜çº§é…ç½®**: å‚è€ƒ `advanced_config.py`

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ä¾èµ–å…³ç³»**: ç¡®ä¿å…ˆå®‰è£…UnslothåŒ…
2. **CUDAç¯å¢ƒ**: éœ€è¦CUDA 11.0+æ”¯æŒ  
3. **å†…å­˜è¦æ±‚**: å»ºè®®æ¯ä¸ªGPUè‡³å°‘8GBæ˜¾å­˜
4. **Pythonç‰ˆæœ¬**: éœ€è¦Python 3.8+
5. **DDPè®­ç»ƒ**: å¤šGPUè®­ç»ƒéœ€è¦ä½¿ç”¨torchrunå¯åŠ¨
6. **æ˜¾å­˜ä¼˜åŒ–**: å»ºè®®ä½¿ç”¨ `load_in_4bit=True` å‡å°‘æ˜¾å­˜å ç”¨
7. **GRPOè®­ç»ƒ**: ä½¿ç”¨vLLMæ—¶éœ€è¦å…ˆå¯åŠ¨æ¨ç†æœåŠ¡ï¼Œæ”¯æŒopen-r1ä¸“ä¸šå¥–åŠ±å‡½æ•°
8. **vLLMæœåŠ¡**: GRPOè®­ç»ƒå‰éœ€è¦å¯åŠ¨vLLMæœåŠ¡ç”¨äºå¿«é€Ÿæ¨ç†

## ğŸ¤ å…¼å®¹æ€§

- âœ… Unsloth 2023.x ç‰ˆæœ¬
- âœ… PyTorch 1.12+
- âœ… CUDA 11.0+
- âœ… Transformers 4.30+

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-06)
- å®Œæ•´çš„å¤šGPUè®­ç»ƒæ”¯æŒ
- æ¨¡å—åŒ–Hookç³»ç»Ÿ
- å†…å­˜ç®¡ç†å’Œä¼˜åŒ–
- å®Œæ•´æµ‹è¯•è¦†ç›–

**æ³¨æ„**: æ­¤åŒ…ä¸ºUnslothçš„å¤–éƒ¨æ‰©å±•ï¼Œä¸ä¼šä¿®æ”¹Unslothæºç ï¼Œç¡®ä¿ä¸ä¸Šæ¸¸ç‰ˆæœ¬çš„å…¼å®¹æ€§ã€‚ 